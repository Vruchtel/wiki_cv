\documentclass[a4paper,10pt]{article}

%%% Работа с русским языком
\usepackage{cmap}					% поиск в PDF
\usepackage{mathtext} 				% русские буквы в формулах
\usepackage[T2A]{fontenc}			% кодировка
\usepackage[utf8]{inputenc}			% кодировка исходного текста
\usepackage[english,russian]{babel}	% локализация и переносы

%%% Дополнительная работа с математикой
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools} % AMS
\usepackage{icomma} % "Умная" запятая: $0,2$ --- число, $0, 2$ --- перечисление

%% Номера формул
%\mathtoolsset{showonlyrefs=true} % Показывать номера только у тех формул, на которые есть \eqref{} в тексте.
%\usepackage{leqno} % Нумерация формул слева

%% Свои команды
\DeclareMathOperator{\sgn}{\mathop{sgn}}

%% Перенос знаков в формулах (по Львовскому)
\newcommand*{\hm}[1]{#1\nobreak\discretionary{}
{\hbox{$\mathsurround=0pt #1$}}{}}

%%% Работа с картинками
\usepackage{graphicx}  % Для вставки рисунков
\graphicspath{{images/}{images2/}}  % папки с картинками
\setlength\fboxsep{3pt} % Отступ рамки \fbox{} от рисунка
\setlength\fboxrule{1pt} % Толщина линий рамки \fbox{}
\usepackage{wrapfig} % Обтекание рисунков текстом

%%% Работа с таблицами
\usepackage{array,tabularx,tabulary,booktabs} % Дополнительная работа с таблицами
\usepackage{longtable}  % Длинные таблицы
\usepackage{multirow} % Слияние строк в таблице

%%% Теоремы
\theoremstyle{plain} % Это стиль по умолчанию, его можно не переопределять.
\newtheorem{theorem}{Теорема}[section]
\newtheorem{proposition}[theorem]{Утверждение}
 
\theoremstyle{definition} % "Определение"
\newtheorem{corollary}{Следствие}[theorem]
\newtheorem{problem}{Задача}[section]
 
\theoremstyle{remark} % "Примечание"
\newtheorem*{nonum}{Решение}

%%% Программирование
\usepackage{etoolbox} % логические операторы

%%% Страница
\usepackage{extsizes} % Возможность сделать 14-й шрифт
\usepackage{geometry} % Простой способ задавать поля
	\geometry{top=15mm}
	\geometry{bottom=15mm}
	\geometry{left=15mm}
	\geometry{right=15mm}
 %
\usepackage{fancyhdr} % Колонтитулы
 	%\pagestyle{headings}
 	\renewcommand{\headrulewidth}{0mm}  % Толщина линейки, отчеркивающей верхний колонтитул
 	%\lfoot{Нижний левый}
 	%\rfoot{Нижний правый}
 	%\rhead{Верхний правый}
 	%\chead{Верхний в центре}
 	%\lhead{Верхний левый}
 	% \cfoot{Нижний в центре} % По умолчанию здесь номер страницы
    
\usepackage{setspace} % Интерлиньяж
%\onehalfspacing % Интерлиньяж 1.5
%\doublespacing % Интерлиньяж 2
%\singlespacing % Интерлиньяж 1

\usepackage{lastpage} % Узнать, сколько всего страниц в документе.

\usepackage{soul} % Модификаторы начертания

\usepackage{hyperref}
\usepackage[usenames,dvipsnames,svgnames,table,rgb]{xcolor}
\hypersetup{				% Гиперссылки
    unicode=true,           % русские буквы в раздела PDF
    pdftitle={Заголовок},   % Заголовок
    pdfauthor={Автор},      % Автор
    pdfsubject={Тема},      % Тема
    pdfcreator={Создатель}, % Создатель
    pdfproducer={Производитель}, % Производитель
    pdfkeywords={keyword1} {key2} {key3}, % Ключевые слова
    colorlinks=true,       	% false: ссылки в рамках; true: цветные ссылки
    linkcolor=red,          % внутренние ссылки
    citecolor=green,        % на библиографию
    filecolor=magenta,      % на файлы
    urlcolor=blue           % на URL
}

%\renewcommand{\familydefault}{\sfdefault} % Начертание шрифта

\usepackage{multicol} % Несколько колонок

% отступ у первого абзаца
\usepackage[indentfirst]{titlesec}

\title{Другие методы обучения нейросетей}
\author{Вручтель Серафима. Группа М05-895б.}

\begin{document} % конец преамбулы, начало документа

\maketitle

\section{Введение}

Самым популярным методом обучения нейронных сетей является Back Propogation. Основная его <<фишка>> "--- это chain rule, благодаря которому и происходит и обратное распространение ошибки.

Но помимо Back Propogation существуют также и другие методы обучения нейросетей. В этой статье мы попробуем разобраться, какие ещё есть способы обучения искусственных нейросетей, и в чём всё-таки их превзошёл Back Propogation.

\section{Обзор методов}

\subsection{Метод Хебба}

Метод Хебба был создан в 1949 году на основе физиологических и психологических исследований и стал первым способом обучения нейронных сетей.

К 1949 году Хебб сформулировал <<универсальный нейрофизиологический постулат>>, суть которого заключается в следующем: <<Если нейрон A находится достаточно близко к нейрону B и часто принимает участие в его возбуждении, то можно наблюдать процесс роста или метаболических изменений в одном или в обоих нейронах, ведущий к увеличению эффективности A, как одного из нейронов, возбуждающих B>>.

Обычно для обучения нейросетей, основываясь на методе Хебба, используют следующие правила корректировки (предполагается, что каждый нейрон на выходе выдаёт либо логический ноль, либо логическую единицу):

\textbf{Первое правило:} Если сигнал на выходе из нейрона неверен и при этом равен нулю, \textbf{увеличить} веса тех входов, на которые была подана единица.

\textbf{Второе правило:} Если сигнал на выходе из нейрона неверен и при этом равен единице, \textbf{уменьшить} веса тех входов, на которые была подана единица.

Правила последовательно применяются для всех элементов из обучающей выборки.

\subsection{Генетические алгоритмы}

Алгоритмы этого вида являются стохастическими и, можно сказать, используют теорию эволюции.

Пусть есть множество алгоритмов, которое мы назовём популяцией. Для каждой <<особи>> $p$ в популяции можно вычислить значение некоторой функции ошибки $E(p)$. <<Особи>> могут размножаться, причём вероятность их размножения зависит от значения $E(p)$ "--- чем меньше ошибка, тем выше вероятность размножения. Например, если ошибка некоторого алгоритма достаточно велика, соответствующая <<особь>> с большой вероятностью может погибнуть не произведя на свет <<потомства>> (Размножаться особи могут как скрещиванием, так и делением, в зависимости от выбранного подхода).

Потомство может мутировать. Это осуществляется с помощью случайных модификаций весов нейросети. Наиболее удачные мутации, дающие наименьшую ошибку, будут сохраняться, а наименее удачные - уничтожаться.

В итоге может быть получен алгоритм с минимальным значением ошибки $E$.

\subsection{Ньютоновский метод}

Метод Ньютона похож на метод обратного распространения ошибки с некоторым существенным изменением. Его суть заключается в поиске лучшего направления обучения с использованием вторых производных функции потерь (гессиана).

Пусть $w_i$ "--- вектор весов нейросети на шаге обучения $i$. Тогда шаг метода Ньютона осуществляется следующим образом:

\begin{equation*}
    w_{i + 1} = w_i - (H_i^{-1} g_i) \cdot \eta_i
\end{equation*}
где $H_i = H(f(w_i))$ "--- матрица Гессе, $g_i = \nabla f(w_i)$ "--- производная функции потерь на i-й итерации, $\eta_i$ "--- learning rate.

Во многих случаях метод Ньютона сходится быстро, но требует больших затрат из-за вычисления гессиана и обратной матрицы. Пытаясь избежать вычисления матрицы Гессе, изобретают различные квазиньютоновские методы.

\subsubsection*{Квазиньютоновский метод}

Суть этого метода заключается в приближённом вычислении обратной матрицы Гессе на каждой итерации работы алгоритма, причём для вычисления приближённой обратной матрицы необходимы только первые производные функции потерь. Гессиан аппроксимируется некоторой матрицей $G$, и шаг метода выглядит следующим образом:

\begin{equation*}
    w_{i + 1} = w_i - (G_i \cdot g_i) \cdot \eta_i
\end{equation*}

Приближённую обратную матрицу Гессе G можно вычислять разными способами. Два самых популярных варианта: формула Давиона-Флетчера-Пауэлла и формула Бройдена-Флетчера-Гольдфарба-Шанно.

\subsection{Моменты}

Моменты применяются совместно с градиентным спуском. Они позволяют придать векторам градиентов <<ускорение>> в нужном направлении, благодаря чему метод сходится быстрее. На самом деле, именно этот способ чаще всего и используется для оптимизации современных нейросетей (см., например, Nesterov Momentum, SGD Momentum и пр.).

% Экспоненциально взвешенные средние???

Пусть у нас есть зашумлённая последовательность чисел $S_i$. Попытаемся понять, как выглядела исходная последовательность без шума. Для этого построим новую последовательность чисел $V_i$:

\begin{equation*}
    V_i = \beta V_{i - 1} + (1 - \beta) S_i, \\\ \beta \in [0, \dots, 1]
\end{equation*}

Здесь $\beta$ выступает в качестве гиперпараметра.

Так мы получим, что i-е значение последовательности $V_i$ зависит от всех предыдущих значений оригинальной последовательности. При этом наиболее <<недавним>> значениям $S_i$ придаётся больший вес.

Момент получается применением записанной выше формулы с использованием шагов градиента функции потерь в качестве исходной последовательности. Таким образом момент позволяет регулировать направление и скорость градиентного спуска, придавая ему некоторую инерцию. Например, SGD momentum выглядит следующим образом:

\begin{equation*}
    V_i = \beta V_{i - 1} + (1 - \beta) \nabla L_W(W, X, y)
\end{equation*}

\begin{equation*}
    W = W - \alpha V_i
\end{equation*}

Здесь $L$ "--- функция потерь, а $\alpha$ "--- learning rate.

\section{Заключение}

Как можно видеть, существует много различных способов обучения нейронных сетей. Но чем же всё-таки оказался так хорош Back Propogation?

В отличие от остальных алгоритмов, таких как, например, генетический алгоритм или ньютоновский метод, Back Propogation требует меньше ресурсов для вычислений. Также он имеет существенное преимущество в скорости по сравнению c, например, методом Хебба или же, снова, генетическим алгоритмом. С применением метода обратного распространения ошибки нейросеть обучается намного быстрее.

Ну и, как говорится, we user back propogation because

(1) we don't have anything better than back propogation,

(2) it is working.

\end{document}
